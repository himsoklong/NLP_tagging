{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T13:19:25.330592Z",
     "start_time": "2022-11-18T13:19:25.321943Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader,Dataset, random_split, Subset\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import torch\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T13:19:26.926918Z",
     "start_time": "2022-11-18T13:19:26.919237Z"
    }
   },
   "outputs": [],
   "source": [
    "def _find_files(directory, pattern='*.final'):\n",
    "        \"\"\"Recursively find all files matching the pattern.\"\"\"\n",
    "        file_path_list = []\n",
    "        for root, dirnames, filenames in os.walk(directory):\n",
    "            for filename in fnmatch.filter(filenames, pattern):\n",
    "                file_path_list.append(os.path.join(root, filename))\n",
    "        return file_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T13:23:21.433526Z",
     "start_time": "2022-11-18T13:23:21.424322Z"
    }
   },
   "outputs": [],
   "source": [
    "file_list = _find_files('../Dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T17:35:22.055152Z",
     "start_time": "2022-11-16T17:35:22.050209Z"
    }
   },
   "outputs": [],
   "source": [
    "# file = '../Dataset/dev/2019/2019-45-2-293-337.final'\n",
    "# token_label_list = []\n",
    "# with open(file,'r',errors='replace') as f:\n",
    "#         for token_label in f.read().splitlines():\n",
    "#             token_label_list.append(token_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T13:42:03.951170Z",
     "start_time": "2022-11-18T13:42:03.909941Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_list = ['UNK','PAD']\n",
    "total_word = []\n",
    "token_label_list = []\n",
    "for file in file_list:\n",
    "#     print(file)\n",
    "    #becasue some file have issue with encoding. so we just replace it to \"?\" if they can encode it.\n",
    "    with open(file,'r', errors='replace') as f:\n",
    "        for token_label in f.read().splitlines():\n",
    "#             print(token_label)\n",
    "            # select exclude empty line because some annotator not follow this rule.\n",
    "            if token_label != '':\n",
    "                # some line does not use tab '\\t'\n",
    "                if not token_label.__contains__('\\t'):\n",
    "    #                 print(token_label)\n",
    "                    token_label_list.append(token_label)\n",
    "                    #split word and term by space\n",
    "                    token = token_label.split()[0]\n",
    "                    word_list.append(token.lower())\n",
    "                elif token_label.__contains__('\\t'):\n",
    "                    token_label_list.append(token_label)\n",
    "                    #split word and term by tab\n",
    "                    token = token_label.split('\\t')[0]\n",
    "                    word_list.append(token.lower())\n",
    "                else:\n",
    "                    print('# '+str(token_label)+file+' #')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T13:42:10.954625Z",
     "start_time": "2022-11-18T13:42:10.948629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26748"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T13:42:26.293186Z",
     "start_time": "2022-11-18T13:42:26.268592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNK',\n",
       " 'PAD',\n",
       " 'translation',\n",
       " 'models',\n",
       " 'used',\n",
       " 'for',\n",
       " 'statistical',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'are',\n",
       " 'compiled',\n",
       " 'from',\n",
       " 'parallel',\n",
       " 'corpora',\n",
       " 'that',\n",
       " 'are',\n",
       " 'manually',\n",
       " 'translated',\n",
       " '.',\n",
       " 'the',\n",
       " 'common',\n",
       " 'assumption',\n",
       " 'is',\n",
       " 'that',\n",
       " 'parallel',\n",
       " 'texts',\n",
       " 'are',\n",
       " 'symmetrical',\n",
       " ':',\n",
       " 'the',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'translation',\n",
       " 'is',\n",
       " 'deemed',\n",
       " 'irrelevant',\n",
       " 'and',\n",
       " 'is',\n",
       " 'consequently',\n",
       " 'ignored',\n",
       " '.',\n",
       " 'much',\n",
       " 'research',\n",
       " 'in',\n",
       " 'translation',\n",
       " 'studies',\n",
       " 'indicates',\n",
       " 'that',\n",
       " 'the',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'translation',\n",
       " 'matters',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'as',\n",
       " 'translated',\n",
       " 'language',\n",
       " '(',\n",
       " 'translationese',\n",
       " ')',\n",
       " 'has',\n",
       " 'many',\n",
       " 'unique',\n",
       " 'properties',\n",
       " '.',\n",
       " 'it',\n",
       " 'has',\n",
       " 'already',\n",
       " 'been',\n",
       " 'shown',\n",
       " 'that',\n",
       " 'phrase',\n",
       " 'tables',\n",
       " 'constructed',\n",
       " 'from',\n",
       " 'parallel',\n",
       " 'corpora',\n",
       " 'translated',\n",
       " 'in',\n",
       " 'the',\n",
       " 'same',\n",
       " 'direction',\n",
       " 'as',\n",
       " 'the',\n",
       " 'translation',\n",
       " 'task',\n",
       " 'outperform',\n",
       " 'those',\n",
       " 'constructed',\n",
       " 'from',\n",
       " 'corpora',\n",
       " 'translated',\n",
       " 'in',\n",
       " 'the',\n",
       " 'opposite',\n",
       " 'direction',\n",
       " '.',\n",
       " '',\n",
       " 'we',\n",
       " 'reconfirm',\n",
       " 'that',\n",
       " 'this',\n",
       " 'is',\n",
       " 'indeed',\n",
       " 'the',\n",
       " 'case',\n",
       " ',',\n",
       " 'but',\n",
       " 'emphasize',\n",
       " 'the',\n",
       " 'importance',\n",
       " 'of',\n",
       " 'also',\n",
       " 'using',\n",
       " 'texts',\n",
       " 'translated',\n",
       " 'in',\n",
       " 'the',\n",
       " '“',\n",
       " 'wrong',\n",
       " '”',\n",
       " 'direction',\n",
       " '.',\n",
       " 'we',\n",
       " 'take',\n",
       " 'advantage',\n",
       " 'of',\n",
       " 'information',\n",
       " 'pertaining',\n",
       " 'to',\n",
       " 'the',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'translation',\n",
       " 'in',\n",
       " 'constructing',\n",
       " 'phrase',\n",
       " 'tables',\n",
       " 'by',\n",
       " 'adapting',\n",
       " 'the',\n",
       " 'translation',\n",
       " 'model',\n",
       " 'to',\n",
       " 'the',\n",
       " 'special',\n",
       " 'properties',\n",
       " 'of',\n",
       " 'translationese',\n",
       " '.',\n",
       " 'we',\n",
       " 'explore',\n",
       " 'two',\n",
       " 'adaptation',\n",
       " 'techniques',\n",
       " ':',\n",
       " 'first',\n",
       " ',',\n",
       " 'we',\n",
       " 'create',\n",
       " 'a',\n",
       " 'mixture',\n",
       " 'model',\n",
       " 'by',\n",
       " 'interpolating',\n",
       " 'phrase',\n",
       " 'tables',\n",
       " 'trained',\n",
       " 'on',\n",
       " 'texts',\n",
       " 'translated',\n",
       " 'in',\n",
       " 'the',\n",
       " '“',\n",
       " 'right',\n",
       " '”',\n",
       " 'and',\n",
       " 'the',\n",
       " '“',\n",
       " 'wrong',\n",
       " '”',\n",
       " 'directions',\n",
       " '.',\n",
       " 'the',\n",
       " 'weights',\n",
       " 'for',\n",
       " 'the',\n",
       " 'interpolation',\n",
       " 'are',\n",
       " 'determined',\n",
       " 'by',\n",
       " 'minimizing',\n",
       " 'perplexity',\n",
       " '.',\n",
       " 'second',\n",
       " ',',\n",
       " 'we',\n",
       " 'define',\n",
       " 'entropy',\n",
       " '-',\n",
       " 'based',\n",
       " 'measures',\n",
       " 'that',\n",
       " 'estimate',\n",
       " 'the',\n",
       " 'correspondence',\n",
       " 'of',\n",
       " 'target',\n",
       " '-',\n",
       " 'language',\n",
       " 'phrases',\n",
       " 'to',\n",
       " 'translationese',\n",
       " ',',\n",
       " 'thereby',\n",
       " 'eliminating',\n",
       " 'the',\n",
       " 'need',\n",
       " 'to',\n",
       " 'annotate',\n",
       " 'the',\n",
       " 'parallel',\n",
       " 'corpus',\n",
       " 'with',\n",
       " 'information',\n",
       " 'pertaining',\n",
       " 'to',\n",
       " 'the',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'translation',\n",
       " '.',\n",
       " 'we',\n",
       " 'show',\n",
       " 'that',\n",
       " 'incorporating',\n",
       " 'these',\n",
       " 'measures',\n",
       " 'as',\n",
       " 'features',\n",
       " 'in',\n",
       " 'the',\n",
       " 'phrase',\n",
       " 'tables',\n",
       " 'of',\n",
       " 'statistical',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'systems',\n",
       " 'results',\n",
       " 'in',\n",
       " 'consistent',\n",
       " ',',\n",
       " 'statistically',\n",
       " 'significant',\n",
       " 'improvement',\n",
       " 'in',\n",
       " 'the',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'the',\n",
       " 'translation',\n",
       " '.',\n",
       " 'as',\n",
       " 'more',\n",
       " 'and',\n",
       " 'more',\n",
       " 'arabic',\n",
       " 'textual',\n",
       " 'information',\n",
       " 'becomes',\n",
       " 'available',\n",
       " 'through',\n",
       " 'the',\n",
       " 'web',\n",
       " 'in',\n",
       " 'homes',\n",
       " 'and',\n",
       " 'businesses',\n",
       " ',',\n",
       " 'via',\n",
       " 'internet',\n",
       " 'and',\n",
       " 'intranet',\n",
       " 'services',\n",
       " ',',\n",
       " 'there',\n",
       " 'is',\n",
       " 'an',\n",
       " 'urgent',\n",
       " 'need',\n",
       " 'for',\n",
       " 'technologies',\n",
       " 'and',\n",
       " 'tools',\n",
       " 'to',\n",
       " 'process',\n",
       " 'the',\n",
       " 'relevant',\n",
       " 'information',\n",
       " '.',\n",
       " 'named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " '(',\n",
       " 'ner',\n",
       " ')',\n",
       " 'is',\n",
       " 'an',\n",
       " 'information',\n",
       " 'extraction',\n",
       " 'task',\n",
       " 'that',\n",
       " 'has',\n",
       " 'become',\n",
       " 'an',\n",
       " 'integral',\n",
       " 'part',\n",
       " 'of',\n",
       " 'many',\n",
       " 'other',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'nlp',\n",
       " ')',\n",
       " 'tasks',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'and',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " '.',\n",
       " 'arabic',\n",
       " 'ner',\n",
       " 'has',\n",
       " 'begun',\n",
       " 'to',\n",
       " 'receive',\n",
       " 'attention',\n",
       " 'in',\n",
       " 'recent',\n",
       " 'years',\n",
       " '.',\n",
       " 'the',\n",
       " 'characteristics',\n",
       " 'and',\n",
       " 'peculiarities',\n",
       " 'of',\n",
       " 'arabic',\n",
       " ',',\n",
       " 'a',\n",
       " 'member',\n",
       " 'of',\n",
       " 'the',\n",
       " 'semitic',\n",
       " 'languages',\n",
       " 'family',\n",
       " ',',\n",
       " 'make',\n",
       " 'dealing',\n",
       " 'with',\n",
       " 'ner',\n",
       " 'a',\n",
       " 'challenge',\n",
       " '.',\n",
       " 'the',\n",
       " 'performance',\n",
       " 'of',\n",
       " 'an',\n",
       " 'arabic',\n",
       " 'ner',\n",
       " 'component',\n",
       " 'affects',\n",
       " 'the',\n",
       " 'overall',\n",
       " 'performance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'nlp',\n",
       " 'system',\n",
       " 'in',\n",
       " 'a',\n",
       " 'positive',\n",
       " 'manner',\n",
       " '.',\n",
       " 'this',\n",
       " 'article',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'describe',\n",
       " 'and',\n",
       " 'detail',\n",
       " 'the',\n",
       " 'recent',\n",
       " 'increase',\n",
       " 'in',\n",
       " 'interest',\n",
       " 'and',\n",
       " 'progress',\n",
       " 'made',\n",
       " 'in',\n",
       " 'arabic',\n",
       " 'ner',\n",
       " 'research',\n",
       " '.',\n",
       " 'the',\n",
       " 'importance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ner',\n",
       " 'task',\n",
       " 'is',\n",
       " 'demonstrated',\n",
       " ',',\n",
       " 'the',\n",
       " 'main',\n",
       " 'characteristics',\n",
       " 'of',\n",
       " 'the',\n",
       " 'arabic',\n",
       " 'language',\n",
       " 'are',\n",
       " 'highlighted',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'aspects',\n",
       " 'of',\n",
       " 'standardization',\n",
       " 'in',\n",
       " 'annotating',\n",
       " 'named',\n",
       " 'entities',\n",
       " 'are',\n",
       " 'illustrated',\n",
       " '.',\n",
       " 'moreover',\n",
       " ',',\n",
       " 'the',\n",
       " 'different',\n",
       " 'arabic',\n",
       " 'linguistic',\n",
       " 'resources',\n",
       " 'are',\n",
       " 'presented',\n",
       " 'and',\n",
       " 'the',\n",
       " 'approaches',\n",
       " 'used',\n",
       " 'in',\n",
       " 'arabic',\n",
       " 'ner',\n",
       " 'field',\n",
       " 'are',\n",
       " 'explained',\n",
       " '.',\n",
       " 'the',\n",
       " 'features',\n",
       " 'of',\n",
       " 'common',\n",
       " 'tools',\n",
       " 'used',\n",
       " 'in',\n",
       " 'arabic',\n",
       " 'ner',\n",
       " 'are',\n",
       " 'described',\n",
       " ',',\n",
       " 'and',\n",
       " 'standard',\n",
       " 'evaluation',\n",
       " 'metrics',\n",
       " 'are',\n",
       " 'illustrated',\n",
       " '.',\n",
       " 'in',\n",
       " 'addition',\n",
       " ',',\n",
       " 'a',\n",
       " 'review',\n",
       " 'of',\n",
       " 'the',\n",
       " 'state',\n",
       " 'of',\n",
       " 'the',\n",
       " 'art',\n",
       " 'of',\n",
       " 'arabic',\n",
       " 'ner',\n",
       " 'research',\n",
       " 'is',\n",
       " 'discussed',\n",
       " '.',\n",
       " 'finally',\n",
       " ',',\n",
       " 'we',\n",
       " 'present',\n",
       " 'our',\n",
       " 'conclusions',\n",
       " '.',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'presentation',\n",
       " ',',\n",
       " 'illustrative',\n",
       " 'examples',\n",
       " 'are',\n",
       " 'used',\n",
       " 'for',\n",
       " 'clarification',\n",
       " '.',\n",
       " 'we',\n",
       " 'present',\n",
       " 'a',\n",
       " 'statistical',\n",
       " 'parsing',\n",
       " 'framework',\n",
       " 'for',\n",
       " 'sentence',\n",
       " '-',\n",
       " 'level',\n",
       " 'sentiment',\n",
       " 'classification',\n",
       " 'in',\n",
       " 'this',\n",
       " 'article',\n",
       " '.',\n",
       " 'unlike',\n",
       " 'previous',\n",
       " 'works',\n",
       " 'that',\n",
       " 'use',\n",
       " 'syntactic',\n",
       " 'parsing',\n",
       " 'results',\n",
       " 'for',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'we',\n",
       " 'develop',\n",
       " 'a',\n",
       " 'statistical',\n",
       " 'parser',\n",
       " 'to',\n",
       " 'directly',\n",
       " 'analyze',\n",
       " 'the',\n",
       " 'sentiment',\n",
       " 'structure',\n",
       " 'of',\n",
       " 'a',\n",
       " 'sentence',\n",
       " '.',\n",
       " 'we',\n",
       " 'show',\n",
       " 'that',\n",
       " 'complicated',\n",
       " 'phenomena',\n",
       " 'in',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " '(',\n",
       " 'e.g.',\n",
       " ',',\n",
       " 'negation',\n",
       " ',',\n",
       " 'intensification',\n",
       " ',',\n",
       " 'and',\n",
       " 'contrast',\n",
       " ')',\n",
       " 'can',\n",
       " 'be',\n",
       " 'handled',\n",
       " 'the',\n",
       " 'same',\n",
       " 'way',\n",
       " 'as',\n",
       " 'simple',\n",
       " 'and',\n",
       " 'straightforward',\n",
       " 'sentiment',\n",
       " 'expressions',\n",
       " 'in',\n",
       " 'a',\n",
       " 'unified',\n",
       " 'and',\n",
       " 'probabilistic',\n",
       " 'way',\n",
       " '.',\n",
       " 'we',\n",
       " 'formulate',\n",
       " 'the',\n",
       " 'sentiment',\n",
       " 'grammar',\n",
       " 'upon',\n",
       " 'context',\n",
       " '-',\n",
       " 'free',\n",
       " 'grammars',\n",
       " '(',\n",
       " 'cfgs',\n",
       " ')',\n",
       " ',',\n",
       " 'and',\n",
       " 'provide',\n",
       " 'a',\n",
       " 'formal',\n",
       " 'description',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sentiment',\n",
       " 'parsing',\n",
       " 'framework',\n",
       " '.',\n",
       " 'we',\n",
       " 'develop',\n",
       " 'the',\n",
       " 'parsing',\n",
       " 'model',\n",
       " 'to',\n",
       " 'obtain',\n",
       " 'possible',\n",
       " 'sentiment',\n",
       " 'parse',\n",
       " 'trees',\n",
       " 'for',\n",
       " 'a',\n",
       " 'sentence',\n",
       " ',',\n",
       " 'from',\n",
       " 'which',\n",
       " 'the',\n",
       " 'polarity',\n",
       " 'model',\n",
       " 'is',\n",
       " 'proposed',\n",
       " 'to',\n",
       " 'derive',\n",
       " 'the',\n",
       " 'sentiment',\n",
       " 'strength',\n",
       " 'and',\n",
       " 'polarity',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'ranking',\n",
       " 'model',\n",
       " 'is',\n",
       " 'dedicated',\n",
       " 'to',\n",
       " 'selecting',\n",
       " 'the',\n",
       " 'best',\n",
       " 'sentiment',\n",
       " 'tree',\n",
       " '.',\n",
       " 'we',\n",
       " 'train',\n",
       " 'the',\n",
       " 'parser',\n",
       " 'directly',\n",
       " 'from',\n",
       " 'examples',\n",
       " 'of',\n",
       " 'sentences',\n",
       " 'annotated',\n",
       " 'only',\n",
       " 'with',\n",
       " 'sentiment',\n",
       " 'polarity',\n",
       " 'labels',\n",
       " 'but',\n",
       " 'without',\n",
       " 'any',\n",
       " 'syntactic',\n",
       " 'annotations',\n",
       " 'or',\n",
       " 'polarity',\n",
       " 'annotations',\n",
       " 'of',\n",
       " 'constituents',\n",
       " 'within',\n",
       " 'sentences',\n",
       " '.',\n",
       " 'therefore',\n",
       " 'we',\n",
       " 'can',\n",
       " 'obtain',\n",
       " 'training',\n",
       " 'data',\n",
       " 'easily',\n",
       " '.',\n",
       " '',\n",
       " 'in',\n",
       " 'particular',\n",
       " ',',\n",
       " 'we',\n",
       " 'train',\n",
       " 'a',\n",
       " 'sentiment',\n",
       " 'parser',\n",
       " ',',\n",
       " 's.parser',\n",
       " ',',\n",
       " 'from',\n",
       " 'a',\n",
       " 'large',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'review',\n",
       " 'sentences',\n",
       " 'with',\n",
       " 'users',\n",
       " \"'\",\n",
       " 'ratings',\n",
       " 'as',\n",
       " 'rough',\n",
       " 'sentiment',\n",
       " 'polarity',\n",
       " 'labels',\n",
       " '.',\n",
       " 'extensive',\n",
       " 'experiments',\n",
       " 'on',\n",
       " 'existing',\n",
       " 'benchmark',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'show',\n",
       " 'significant',\n",
       " 'improvements',\n",
       " 'over',\n",
       " 'baseline',\n",
       " 'sentiment',\n",
       " 'classification',\n",
       " 'approaches',\n",
       " '.',\n",
       " 'this',\n",
       " 'article',\n",
       " 'deals',\n",
       " 'with',\n",
       " 'deverbal',\n",
       " 'nominalizations',\n",
       " 'in',\n",
       " 'spanish',\n",
       " ';',\n",
       " 'concretely',\n",
       " ',',\n",
       " 'we',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'the',\n",
       " 'denotative',\n",
       " 'distinction',\n",
       " 'between',\n",
       " 'event',\n",
       " 'and',\n",
       " 'result',\n",
       " 'nominalizations',\n",
       " '.',\n",
       " 'the',\n",
       " 'goals',\n",
       " 'of',\n",
       " 'this',\n",
       " 'work',\n",
       " 'is',\n",
       " 'twofold',\n",
       " ':',\n",
       " 'ﬁrst',\n",
       " ',',\n",
       " 'to',\n",
       " 'detect',\n",
       " 'the',\n",
       " 'most',\n",
       " 'relevant',\n",
       " 'features',\n",
       " 'for',\n",
       " 'this',\n",
       " 'denotative',\n",
       " 'distinction',\n",
       " ';',\n",
       " 'and',\n",
       " ',',\n",
       " 'second',\n",
       " ',',\n",
       " 'to',\n",
       " 'build',\n",
       " 'an',\n",
       " 'automatic',\n",
       " 'classiﬁcation',\n",
       " 'system',\n",
       " 'of',\n",
       " 'deverbal',\n",
       " 'nominalizations',\n",
       " 'according',\n",
       " 'to',\n",
       " 'their',\n",
       " 'denotation',\n",
       " '.',\n",
       " 'we',\n",
       " 'have',\n",
       " 'based',\n",
       " 'our',\n",
       " 'study',\n",
       " 'on',\n",
       " 'theoretical',\n",
       " 'hypotheses',\n",
       " 'dealing',\n",
       " 'with',\n",
       " 'this',\n",
       " 'semantic',\n",
       " 'distinction',\n",
       " 'and',\n",
       " 'we',\n",
       " 'have',\n",
       " 'analyzed',\n",
       " 'them',\n",
       " 'empirically',\n",
       " 'by',\n",
       " 'means',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'techniques',\n",
       " 'which',\n",
       " 'are',\n",
       " 'the',\n",
       " 'basis',\n",
       " 'of',\n",
       " 'the',\n",
       " 'adn',\n",
       " '-',\n",
       " 'classiﬁer',\n",
       " '.',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'ﬁrst',\n",
       " 'tool',\n",
       " 'that',\n",
       " 'aims',\n",
       " 'to',\n",
       " 'automatically',\n",
       " 'classify',\n",
       " 'deverbal',\n",
       " 'nominalizations',\n",
       " 'in',\n",
       " 'event',\n",
       " ',',\n",
       " 'result',\n",
       " ',',\n",
       " 'or',\n",
       " 'underspeciﬁed',\n",
       " 'denotation',\n",
       " 'types',\n",
       " 'in',\n",
       " 'spanish',\n",
       " '.',\n",
       " 'the',\n",
       " 'adn',\n",
       " '-',\n",
       " 'classiﬁer',\n",
       " 'has',\n",
       " 'helped',\n",
       " 'us',\n",
       " 'to',\n",
       " 'quantitatively',\n",
       " 'evaluate',\n",
       " 'the',\n",
       " 'validity',\n",
       " 'of',\n",
       " 'our',\n",
       " 'claims',\n",
       " 'regarding',\n",
       " 'deverbal',\n",
       " 'nominalizations',\n",
       " '.',\n",
       " 'we',\n",
       " 'set',\n",
       " 'up',\n",
       " 'a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'experiments',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'test',\n",
       " 'the',\n",
       " 'adn',\n",
       " '-',\n",
       " 'classiﬁer',\n",
       " 'with',\n",
       " 'different',\n",
       " 'models',\n",
       " 'and',\n",
       " 'in',\n",
       " 'different',\n",
       " 'realistic',\n",
       " 'scenarios',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'the',\n",
       " 'knowledge',\n",
       " 'resources',\n",
       " 'and',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processors',\n",
       " 'available',\n",
       " '.',\n",
       " 'the',\n",
       " 'adn',\n",
       " '-',\n",
       " 'classiﬁer',\n",
       " 'achieved',\n",
       " 'good',\n",
       " 'results',\n",
       " '(',\n",
       " '87.20',\n",
       " '%',\n",
       " 'accuracy',\n",
       " ')',\n",
       " '.',\n",
       " 'systems',\n",
       " 'based',\n",
       " 'on',\n",
       " 'synchronous',\n",
       " 'grammars',\n",
       " 'and',\n",
       " 'tree',\n",
       " 'transducers',\n",
       " 'promise',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'the',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'statistical',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'output',\n",
       " ',',\n",
       " 'but',\n",
       " 'are',\n",
       " 'often',\n",
       " 'very',\n",
       " 'computationally',\n",
       " 'intensive',\n",
       " '.',\n",
       " 'the',\n",
       " 'complexity',\n",
       " 'is',\n",
       " 'exponential',\n",
       " 'in',\n",
       " 'the',\n",
       " 'size',\n",
       " 'of',\n",
       " 'individual',\n",
       " 'grammar',\n",
       " 'rules',\n",
       " 'due',\n",
       " 'to',\n",
       " 'arbitrary',\n",
       " 're',\n",
       " 'orderings',\n",
       " 'between',\n",
       " 'the',\n",
       " 'two',\n",
       " 'languages',\n",
       " '.',\n",
       " 'we',\n",
       " 'develop',\n",
       " 'a',\n",
       " 'theory',\n",
       " 'of',\n",
       " 'binarization',\n",
       " 'for',\n",
       " 'synchronous',\n",
       " 'context',\n",
       " 'free',\n",
       " 'grammars',\n",
       " 'and',\n",
       " 'present',\n",
       " 'a',\n",
       " 'linear',\n",
       " 'time',\n",
       " 'algorithm',\n",
       " 'for',\n",
       " 'binarizing',\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(word_list) services\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T13:42:47.372393Z",
     "start_time": "2022-11-18T13:42:47.356469Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "\n",
    "for index,word in enumerate(word_list):\n",
    "    vocab[word] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T13:42:49.593554Z",
     "start_time": "2022-11-18T13:42:49.588682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3367"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T13:45:48.178984Z",
     "start_time": "2022-11-18T13:45:48.145328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNK': 0,\n",
       " 'PAD': 1,\n",
       " 'translation': 26240,\n",
       " 'models': 26459,\n",
       " 'used': 26665,\n",
       " 'for': 26731,\n",
       " 'statistical': 26596,\n",
       " 'machine': 26239,\n",
       " 'are': 26699,\n",
       " 'compiled': 23547,\n",
       " 'from': 26291,\n",
       " 'parallel': 23806,\n",
       " 'corpora': 26628,\n",
       " 'that': 26740,\n",
       " 'manually': 24604,\n",
       " 'translated': 23642,\n",
       " '.': 26747,\n",
       " 'the': 26732,\n",
       " 'common': 22420,\n",
       " 'assumption': 7526,\n",
       " 'is': 26677,\n",
       " 'texts': 24585,\n",
       " 'symmetrical': 27,\n",
       " ':': 26510,\n",
       " 'direction': 230,\n",
       " 'of': 26734,\n",
       " 'deemed': 2938,\n",
       " 'irrelevant': 35,\n",
       " 'and': 26745,\n",
       " 'consequently': 22495,\n",
       " 'ignored': 20444,\n",
       " 'much': 26212,\n",
       " 'research': 26366,\n",
       " 'in': 26737,\n",
       " 'studies': 26170,\n",
       " 'indicates': 13207,\n",
       " 'matters': 52,\n",
       " ',': 26655,\n",
       " 'however': 22521,\n",
       " 'as': 26535,\n",
       " 'language': 26350,\n",
       " '(': 26412,\n",
       " 'translationese': 214,\n",
       " ')': 26414,\n",
       " 'has': 25812,\n",
       " 'many': 25638,\n",
       " 'unique': 22234,\n",
       " 'properties': 22511,\n",
       " 'it': 26630,\n",
       " 'already': 69,\n",
       " 'been': 25813,\n",
       " 'shown': 24472,\n",
       " 'phrase': 22854,\n",
       " 'tables': 245,\n",
       " 'constructed': 25100,\n",
       " 'same': 24042,\n",
       " 'task': 25874,\n",
       " 'outperform': 24152,\n",
       " 'those': 26327,\n",
       " 'opposite': 96,\n",
       " '': 25606,\n",
       " 'we': 26709,\n",
       " 'reconfirm': 101,\n",
       " 'this': 26488,\n",
       " 'indeed': 22503,\n",
       " 'case': 19928,\n",
       " 'but': 26016,\n",
       " 'emphasize': 110,\n",
       " 'importance': 23432,\n",
       " 'also': 26466,\n",
       " 'using': 26560,\n",
       " '“': 26128,\n",
       " 'wrong': 21662,\n",
       " '”': 26130,\n",
       " 'take': 23071,\n",
       " 'advantage': 14757,\n",
       " 'information': 25474,\n",
       " 'pertaining': 227,\n",
       " 'to': 26717,\n",
       " 'constructing': 21080,\n",
       " 'by': 26559,\n",
       " 'adapting': 22817,\n",
       " 'model': 25981,\n",
       " 'special': 24525,\n",
       " 'explore': 23506,\n",
       " 'two': 25509,\n",
       " 'adaptation': 24478,\n",
       " 'techniques': 25795,\n",
       " 'first': 24864,\n",
       " 'create': 23529,\n",
       " 'a': 26738,\n",
       " 'mixture': 163,\n",
       " 'interpolating': 166,\n",
       " 'trained': 18617,\n",
       " 'on': 26660,\n",
       " 'right': 25701,\n",
       " 'directions': 16682,\n",
       " 'weights': 186,\n",
       " 'interpolation': 189,\n",
       " 'determined': 13533,\n",
       " 'minimizing': 8071,\n",
       " 'perplexity': 21323,\n",
       " 'second': 24882,\n",
       " 'define': 24605,\n",
       " 'entropy': 19498,\n",
       " '-': 26680,\n",
       " 'based': 26659,\n",
       " 'measures': 26637,\n",
       " 'estimate': 17481,\n",
       " 'correspondence': 14612,\n",
       " 'target': 24067,\n",
       " 'phrases': 20417,\n",
       " 'thereby': 16764,\n",
       " 'eliminating': 217,\n",
       " 'need': 24734,\n",
       " 'annotate': 15268,\n",
       " 'corpus': 25760,\n",
       " 'with': 26585,\n",
       " 'show': 26710,\n",
       " 'incorporating': 9704,\n",
       " 'these': 26712,\n",
       " 'features': 24609,\n",
       " 'systems': 25884,\n",
       " 'results': 26662,\n",
       " 'consistent': 20546,\n",
       " 'statistically': 4987,\n",
       " 'significant': 24681,\n",
       " 'improvement': 24682,\n",
       " 'quality': 24916,\n",
       " 'more': 26213,\n",
       " 'arabic': 21785,\n",
       " 'textual': 25500,\n",
       " 'becomes': 23270,\n",
       " 'available': 25081,\n",
       " 'through': 25082,\n",
       " 'web': 11316,\n",
       " 'homes': 278,\n",
       " 'businesses': 280,\n",
       " 'via': 23420,\n",
       " 'internet': 283,\n",
       " 'intranet': 285,\n",
       " 'services': 286,\n",
       " 'there': 23927,\n",
       " 'an': 26503,\n",
       " 'urgent': 291,\n",
       " 'technologies': 24716,\n",
       " 'tools': 25492,\n",
       " 'process': 26563,\n",
       " 'relevant': 21276,\n",
       " 'named': 16549,\n",
       " 'entity': 16603,\n",
       " 'recognition': 26448,\n",
       " 'ner': 495,\n",
       " 'extraction': 24428,\n",
       " 'become': 26554,\n",
       " 'integral': 9743,\n",
       " 'part': 26593,\n",
       " 'other': 26558,\n",
       " 'natural': 26349,\n",
       " 'processing': 26351,\n",
       " 'nlp': 26303,\n",
       " 'tasks': 25628,\n",
       " 'such': 26402,\n",
       " 'retrieval': 25248,\n",
       " 'begun': 2051,\n",
       " 'receive': 344,\n",
       " 'attention': 22038,\n",
       " 'recent': 23871,\n",
       " 'years': 10954,\n",
       " 'characteristics': 26313,\n",
       " 'peculiarities': 353,\n",
       " 'member': 358,\n",
       " 'semitic': 361,\n",
       " 'languages': 24665,\n",
       " 'family': 25187,\n",
       " 'make': 23476,\n",
       " 'dealing': 15241,\n",
       " 'challenge': 22476,\n",
       " 'performance': 25313,\n",
       " 'component': 11377,\n",
       " 'affects': 10578,\n",
       " 'overall': 26014,\n",
       " 'system': 23794,\n",
       " 'positive': 10060,\n",
       " 'manner': 14023,\n",
       " 'article': 26489,\n",
       " 'attempts': 24440,\n",
       " 'describe': 21106,\n",
       " 'detail': 22320,\n",
       " 'increase': 2564,\n",
       " 'interest': 26231,\n",
       " 'progress': 405,\n",
       " 'made': 19078,\n",
       " 'demonstrated': 11720,\n",
       " 'main': 21732,\n",
       " 'highlighted': 14812,\n",
       " 'aspects': 18598,\n",
       " 'standardization': 435,\n",
       " 'annotating': 20509,\n",
       " 'entities': 24369,\n",
       " 'illustrated': 25570,\n",
       " 'moreover': 23291,\n",
       " 'different': 25631,\n",
       " 'linguistic': 26357,\n",
       " 'resources': 24655,\n",
       " 'presented': 24314,\n",
       " 'approaches': 26306,\n",
       " 'field': 23832,\n",
       " 'explained': 1785,\n",
       " 'described': 22318,\n",
       " 'standard': 25084,\n",
       " 'evaluation': 26519,\n",
       " 'metrics': 21860,\n",
       " 'addition': 24237,\n",
       " 'review': 9298,\n",
       " 'state': 26052,\n",
       " 'art': 25882,\n",
       " 'discussed': 14875,\n",
       " 'finally': 22290,\n",
       " 'present': 26684,\n",
       " 'our': 26606,\n",
       " 'conclusions': 15984,\n",
       " 'throughout': 17827,\n",
       " 'presentation': 13485,\n",
       " 'illustrative': 511,\n",
       " 'examples': 20233,\n",
       " 'clarification': 516,\n",
       " 'parsing': 26237,\n",
       " 'framework': 26687,\n",
       " 'sentence': 26279,\n",
       " 'level': 25288,\n",
       " 'sentiment': 24430,\n",
       " 'classification': 24592,\n",
       " 'unlike': 534,\n",
       " 'previous': 24308,\n",
       " 'works': 2779,\n",
       " 'use': 26049,\n",
       " 'syntactic': 26287,\n",
       " 'analysis': 25581,\n",
       " 'develop': 21044,\n",
       " 'parser': 23571,\n",
       " 'directly': 13313,\n",
       " 'analyze': 21684,\n",
       " 'structure': 25117,\n",
       " 'complicated': 12413,\n",
       " 'phenomena': 26323,\n",
       " 'e.g.': 12422,\n",
       " 'negation': 22718,\n",
       " 'intensification': 574,\n",
       " 'contrast': 23598,\n",
       " 'can': 26663,\n",
       " 'be': 26664,\n",
       " 'handled': 14521,\n",
       " 'way': 26739,\n",
       " 'simple': 26562,\n",
       " 'straightforward': 22544,\n",
       " 'expressions': 24629,\n",
       " 'unified': 25368,\n",
       " 'probabilistic': 19512,\n",
       " 'formulate': 25477,\n",
       " 'grammar': 26101,\n",
       " 'upon': 603,\n",
       " 'context': 25994,\n",
       " 'free': 25164,\n",
       " 'grammars': 26148,\n",
       " 'cfgs': 609,\n",
       " 'provide': 26727,\n",
       " 'formal': 26369,\n",
       " 'description': 19031,\n",
       " 'obtain': 23750,\n",
       " 'possible': 26398,\n",
       " 'parse': 21915,\n",
       " 'trees': 26707,\n",
       " 'which': 26693,\n",
       " 'polarity': 10093,\n",
       " 'proposed': 24973,\n",
       " 'derive': 8027,\n",
       " 'strength': 25464,\n",
       " 'ranking': 22461,\n",
       " 'dedicated': 8709,\n",
       " 'selecting': 3114,\n",
       " 'best': 22436,\n",
       " 'tree': 26392,\n",
       " 'train': 24742,\n",
       " 'sentences': 25763,\n",
       " 'annotated': 25759,\n",
       " 'only': 23550,\n",
       " 'labels': 24861,\n",
       " 'without': 26576,\n",
       " 'any': 26268,\n",
       " 'annotations': 24765,\n",
       " 'or': 26067,\n",
       " 'constituents': 25698,\n",
       " 'within': 25691,\n",
       " 'therefore': 21982,\n",
       " 'training': 26063,\n",
       " 'data': 26616,\n",
       " 'easily': 6190,\n",
       " 'particular': 26321,\n",
       " 's.parser': 712,\n",
       " 'large': 26203,\n",
       " 'amount': 24805,\n",
       " 'users': 23733,\n",
       " \"'\": 13625,\n",
       " 'ratings': 22650,\n",
       " 'rough': 726,\n",
       " 'extensive': 25580,\n",
       " 'experiments': 24926,\n",
       " 'existing': 25278,\n",
       " 'benchmark': 17220,\n",
       " 'sets': 24059,\n",
       " 'improvements': 23819,\n",
       " 'over': 26482,\n",
       " 'baseline': 24154,\n",
       " 'deals': 8446,\n",
       " 'deverbal': 884,\n",
       " 'nominalizations': 885,\n",
       " 'spanish': 21808,\n",
       " ';': 24971,\n",
       " 'concretely': 17443,\n",
       " 'focus': 20207,\n",
       " 'denotative': 788,\n",
       " 'distinction': 10132,\n",
       " 'between': 24367,\n",
       " 'event': 21168,\n",
       " 'result': 24620,\n",
       " 'goals': 17984,\n",
       " 'work': 24309,\n",
       " 'twofold': 776,\n",
       " 'ﬁrst': 847,\n",
       " 'detect': 781,\n",
       " 'most': 26311,\n",
       " 'build': 22798,\n",
       " 'automatic': 24721,\n",
       " 'classiﬁcation': 799,\n",
       " 'according': 25426,\n",
       " 'their': 25422,\n",
       " 'denotation': 863,\n",
       " 'have': 26714,\n",
       " 'study': 26434,\n",
       " 'theoretical': 21379,\n",
       " 'hypotheses': 816,\n",
       " 'semantic': 25458,\n",
       " 'analyzed': 3587,\n",
       " 'them': 25541,\n",
       " 'empirically': 19294,\n",
       " 'means': 24014,\n",
       " 'learning': 26457,\n",
       " 'basis': 26730,\n",
       " 'adn': 922,\n",
       " 'classiﬁer': 924,\n",
       " 'tool': 22697,\n",
       " 'aims': 20244,\n",
       " 'automatically': 23804,\n",
       " 'classify': 21631,\n",
       " 'underspeciﬁed': 862,\n",
       " 'types': 24632,\n",
       " 'helped': 873,\n",
       " 'us': 25999,\n",
       " 'quantitatively': 876,\n",
       " 'evaluate': 24914,\n",
       " 'validity': 879,\n",
       " 'claims': 882,\n",
       " 'regarding': 12591,\n",
       " 'set': 26617,\n",
       " 'up': 24531,\n",
       " 'series': 25733,\n",
       " 'order': 26176,\n",
       " 'test': 23987,\n",
       " 'realistic': 23482,\n",
       " 'scenarios': 25632,\n",
       " 'depending': 23907,\n",
       " 'knowledge': 26736,\n",
       " 'processors': 918,\n",
       " 'achieved': 21285,\n",
       " 'good': 24937,\n",
       " '87.20': 929,\n",
       " '%': 24956,\n",
       " 'accuracy': 25946,\n",
       " 'synchronous': 12513,\n",
       " 'transducers': 10609,\n",
       " 'promise': 942,\n",
       " 'improve': 26601,\n",
       " 'output': 25929,\n",
       " 'often': 24452,\n",
       " 'very': 26012,\n",
       " 'computationally': 23473,\n",
       " 'intensive': 1771,\n",
       " 'complexity': 22198,\n",
       " 'exponential': 19929,\n",
       " 'size': 19990,\n",
       " 'individual': 25077,\n",
       " 'rules': 26114,\n",
       " 'due': 21660,\n",
       " 'arbitrary': 25047,\n",
       " 're': 23545,\n",
       " 'orderings': 975,\n",
       " 'theory': 25566,\n",
       " 'binarization': 986,\n",
       " 'linear': 19039,\n",
       " 'time': 26679,\n",
       " 'algorithm': 26449,\n",
       " 'binarizing': 999,\n",
       " 'when': 24122,\n",
       " 'scale': 23532,\n",
       " 'found': 7639,\n",
       " 'almost': 14710,\n",
       " 'all': 26221,\n",
       " 'binarizable': 1063,\n",
       " 'resulting': 19639,\n",
       " 'binarized': 1022,\n",
       " 'rule': 24774,\n",
       " 'significantly': 20592,\n",
       " 'improves': 13351,\n",
       " 'speed': 1209,\n",
       " 'syntax': 12782,\n",
       " 'discuss': 26319,\n",
       " 'general': 25645,\n",
       " 'difficult': 22329,\n",
       " 'problem': 25914,\n",
       " 'finding': 23679,\n",
       " 'strategies': 16091,\n",
       " 'non': 26155,\n",
       " 'approximate': 17590,\n",
       " 'polynomial': 20278,\n",
       " 'although': 26034,\n",
       " 'driven': 24745,\n",
       " 'generation': 25329,\n",
       " 'little': 15940,\n",
       " 'paid': 1098,\n",
       " 'fine': 21342,\n",
       " 'grained': 21344,\n",
       " 'interactions': 9590,\n",
       " 'arise': 1106,\n",
       " 'during': 26069,\n",
       " 'microplanning': 1108,\n",
       " 'aggregation': 1266,\n",
       " 'surface': 24199,\n",
       " 'realization': 13509,\n",
       " 'segmentation': 26499,\n",
       " 'propose': 26467,\n",
       " 'hybrid': 23524,\n",
       " 'symbolic': 17957,\n",
       " '/': 24875,\n",
       " 'approach': 26496,\n",
       " 'jointly': 4305,\n",
       " 'constraints': 26270,\n",
       " 'regulating': 1137,\n",
       " 'integrates': 1376,\n",
       " 'small': 24220,\n",
       " 'handwritten': 1147,\n",
       " 'hypertagger': 1152,\n",
       " 'applied': 25799,\n",
       " 'verbalization': 25978,\n",
       " 'base': 15492,\n",
       " 'queries': 1170,\n",
       " 'tested': 19148,\n",
       " '13': 1174,\n",
       " 'bases': 6100,\n",
       " 'demonstrate': 24679,\n",
       " 'domain': 25803,\n",
       " 'independence': 7525,\n",
       " 'several': 26441,\n",
       " 'ways': 24597,\n",
       " 'quantitative': 18594,\n",
       " 'shows': 25637,\n",
       " 'outperforms': 25613,\n",
       " 'purely': 7936,\n",
       " 'terms': 26702,\n",
       " 'both': 26742,\n",
       " 'coverage': 25751,\n",
       " 'human': 25634,\n",
       " 'indicate': 18132,\n",
       " 'find': 25938,\n",
       " 'statistic': 1228,\n",
       " 'fluent': 1233,\n",
       " 'than': 26215,\n",
       " 'template': 1237,\n",
       " 'illustrate': 23542,\n",
       " 'account': 20308,\n",
       " 'various': 26552,\n",
       " 'factors': 20988,\n",
       " 'impacting': 1265,\n",
       " 'applications': 26234,\n",
       " 'entail': 1278,\n",
       " 'classified': 1282,\n",
       " 'distance': 22134,\n",
       " 'how': 26320,\n",
       " 'similar': 25518,\n",
       " 'example': 25848,\n",
       " 'comparing': 23234,\n",
       " 'text': 25922,\n",
       " 'new': 26686,\n",
       " 'document': 25295,\n",
       " 'documents': 11272,\n",
       " 'known': 26120,\n",
       " 'topics': 12396,\n",
       " 'help': 25208,\n",
       " 'identify': 24627,\n",
       " 'topic': 23614,\n",
       " 'typically': 18983,\n",
       " 'distributional': 26735,\n",
       " 'capture': 26718,\n",
       " 'implicit': 21136,\n",
       " 'pieces': 1340,\n",
       " 'do': 26159,\n",
       " 'not': 25527,\n",
       " 'into': 26005,\n",
       " 'relations': 25409,\n",
       " 'words': 25532,\n",
       " 'introduce': 24595,\n",
       " 'alternative': 22648,\n",
       " 'method': 25356,\n",
       " 'measuring': 23991,\n",
       " 'ontological': 1426,\n",
       " 'network': 25899,\n",
       " 'flow': 1412,\n",
       " 'formalism': 26486,\n",
       " 'represent': 25407,\n",
       " 'each': 26557,\n",
       " 'collection': 19540,\n",
       " 'frequency': 11486,\n",
       " 'weighted': 19486,\n",
       " 'concepts': 18026,\n",
       " 'ontology': 9713,\n",
       " 'then': 26318,\n",
       " 'provides': 25546,\n",
       " 'efficient': 23703,\n",
       " 'explicitly': 23379,\n",
       " 'across': 26326,\n",
       " 'variety': 26345,\n",
       " 'performs': 22536,\n",
       " 'well': 26338,\n",
       " 'three': 26031,\n",
       " 'measure': 25462,\n",
       " 'coherence': 25501,\n",
       " 'enables': 21619,\n",
       " 'difference': 17623,\n",
       " 'shedding': 15232,\n",
       " 'light': 26334,\n",
       " 'lends': 13489,\n",
       " 'itself': 19608,\n",
       " 'algorithms': 25621,\n",
       " 'extracting': 23681,\n",
       " 'hyperedge': 1503,\n",
       " 'replacement': 1504,\n",
       " 'hrg': 1507,\n",
       " 'graph': 26411,\n",
       " 'along': 25220,\n",
       " 'vertex': 6355,\n",
       " 'decomposition': 19290,\n",
       " 'smallest': 14544,\n",
       " 'width': 1530,\n",
       " 'relative': 23796,\n",
       " 'one': 25951,\n",
       " 'node': 26474,\n",
       " 'fixed': 19260,\n",
       " 'vertices': 6333,\n",
       " 'input': 25919,\n",
       " 'makes': 1563,\n",
       " 'solve': 25489,\n",
       " 'fact': 26161,\n",
       " 'optimal': 24011,\n",
       " 'decompositions': 1586,\n",
       " 'np': 20817,\n",
       " 'hard': 13229,\n",
       " 'hrgs': 1607,\n",
       " 'where': 25952,\n",
       " 'sequence': 26527,\n",
       " 'intended': 13679,\n",
       " 'application': 25841,\n",
       " 'representation': 25718,\n",
       " 'apply': 24085,\n",
       " 'abstract': 24355,\n",
       " 'meaning': 26358,\n",
       " 'representations': 26355,\n",
       " 'report': 24668,\n",
       " 'phenomenon': 23945,\n",
       " 'oriented': 15814,\n",
       " 'comparative': 24171,\n",
       " 'dominant': 1678,\n",
       " 'english': 25762,\n",
       " 'resource': 23595,\n",
       " 'ers': 1685,\n",
       " 'classic': 1689,\n",
       " 'neural': 26058,\n",
       " 'reflect': 21865,\n",
       " 'factorization': 1716,\n",
       " 'introduced': 21749,\n",
       " 'produce': 24749,\n",
       " 'elementary': 10355,\n",
       " 'dependency': 26706,\n",
       " 'structures': 26713,\n",
       " 'accurately': 18450,\n",
       " 'parsers': 24416,\n",
       " 'conduct': 18501,\n",
       " 'suite': 1741,\n",
       " 'tests': 9671,\n",
       " 'grammatical': 26103,\n",
       " 'competence': 19221,\n",
       " 'despite': 23466,\n",
       " 'comparable': 26555,\n",
       " 'knowledge-': 1767,\n",
       " 'errors': 26078,\n",
       " 'beneficial': 15720,\n",
       " 'depth': 26438,\n",
       " 'representative': 22221,\n",
       " 'leads': 12855,\n",
       " 'development': 21601,\n",
       " 'deduction': 1815,\n",
       " 'describing': 25058,\n",
       " 'operations': 22024,\n",
       " 'combining': 26374,\n",
       " 'values': 26652,\n",
       " 'partial': 5357,\n",
       " 'derivations': 19663,\n",
       " 'some': 25539,\n",
       " 'inside': 1867,\n",
       " 'computed': 25957,\n",
       " 'efficiently': 20274,\n",
       " 'outside': 4041,\n",
       " 'view': 11811,\n",
       " 'out': 22443,\n",
       " 'side': 15641,\n",
       " 'functions': 13265,\n",
       " 'total': 23455,\n",
       " 'value': 1872,\n",
       " 'computation': 25969,\n",
       " 'function': 22623,\n",
       " 'composition': 26733,\n",
       " 'viewpoint': 1889,\n",
       " 'helps': 1890,\n",
       " 'explain': 21388,\n",
       " 'why': 2776,\n",
       " 'settings': 24547,\n",
       " 'lack': 20633,\n",
       " 'semiring': 1911,\n",
       " 'orthographic': 2023,\n",
       " 'similarities': 1950,\n",
       " 'strong': 16324,\n",
       " 'signal': 1921,\n",
       " 'unsupervised': 26495,\n",
       " 'transduction': 1925,\n",
       " 'decipherment': 2018,\n",
       " 'closely': 19820,\n",
       " 'related': 24757,\n",
       " 'pairs': 23759,\n",
       " 'suited': 17343,\n",
       " 'exploiting': 7255,\n",
       " 'log': 7984,\n",
       " 'latent': 14105,\n",
       " 'variables': 25721,\n",
       " 'incorporates': 21438,\n",
       " 'similarity': 25586,\n",
       " 'maximum': 26572,\n",
       " 'likelihood': 1969,\n",
       " 'expensive': 23474,\n",
       " 'address': 25358,\n",
       " 'perform': 26011,\n",
       " 'inference': 26455,\n",
       " 'markov': 25726,\n",
       " 'chain': 1993,\n",
       " 'monte': 1994,\n",
       " 'carlo': 1995,\n",
       " 'sampling': 1996,\n",
       " 'contrastive': 2012,\n",
       " 'divergence': 17601,\n",
       " 'generative': 24283,\n",
       " 'scales': 2029,\n",
       " 'vocabularies': 2032,\n",
       " 'preserves': 2034,\n",
       " 'low-': 2037,\n",
       " 'no': 20196,\n",
       " 'contexts': 26722,\n",
       " 'variation': 26173,\n",
       " 'developing': 12636,\n",
       " 'capable': 16388,\n",
       " 'modifying': 2065,\n",
       " \"'s\": 23586,\n",
       " 'style': 16172,\n",
       " 'either': 26061,\n",
       " 'user': 23186,\n",
       " 'personality': 2238,\n",
       " 'politeness': 2087,\n",
       " 'while': 26330,\n",
       " 'stylistic': 2250,\n",
       " 'control': 24124,\n",
       " 'traditionally': 23838,\n",
       " 'relied': 2094,\n",
       " 'handcrafted': 2096,\n",
       " 'methods': 25317,\n",
       " 'likely': 25434,\n",
       " 'needed': 22025,\n",
       " 'production': 8342,\n",
       " 'range': 24495,\n",
       " 'observed': 14654,\n",
       " 'dialogues': 13395,\n",
       " 'snlg': 2206,\n",
       " 'grammaticality': 2139,\n",
       " 'naturalness': 2141,\n",
       " 'generated': 21828,\n",
       " 'utterances': 15344,\n",
       " 'optimized': 13307,\n",
       " 'perceived': 2167,\n",
       " 'humans': 16598,\n",
       " 'paper': 7212,\n",
       " 'describes': 25682,\n",
       " 'personage': 2181,\n",
       " 'highly': 14694,\n",
       " 'parameterizable': 2185,\n",
       " 'generator': 25088,\n",
       " 'whose': 25405,\n",
       " 'parameters': 18507,\n",
       " 'psychological': 2193,\n",
       " 'findings': 18649,\n",
       " 'about': 24954,\n",
       " 'reflexes': 2198,\n",
       " 'novel': 24596,\n",
       " 'uses': 26347,\n",
       " 'parameter': 26674,\n",
       " 'estimation': 26675,\n",
       " 'predict': 26667,\n",
       " 'decisions': 25453,\n",
       " 'required': 24818,\n",
       " 'convey': 13474,\n",
       " 'combination': 25584,\n",
       " 'scalar': 2230,\n",
       " 'five': 21652,\n",
       " 'dimensions': 25223,\n",
       " 'recognizable': 2249,\n",
       " 'multiple': 24634,\n",
       " 'continuous': 19503,\n",
       " 'computational': 26249,\n",
       " 'cost': 24941,\n",
       " 'incurred': 2266,\n",
       " 'overgeneration': 2268,\n",
       " 'mining': 11311,\n",
       " 'rely': 2854,\n",
       " 'like': 24932,\n",
       " 'speech': 25833,\n",
       " 'tags': 7129,\n",
       " 'stems': 2700,\n",
       " 'high': 26651,\n",
       " 'recently': 16808,\n",
       " 'character': 26549,\n",
       " 'p': 2685,\n",
       " 'grams': 2687,\n",
       " 'native': 19777,\n",
       " 'identification': 24684,\n",
       " 'nli': 19855,\n",
       " 'obtained': 16152,\n",
       " 'string': 22029,\n",
       " 'kernels': 12552,\n",
       " 'kernel': 7313,\n",
       " 'so': 24947,\n",
       " 'questions': 18444,\n",
       " 'remain': 16065,\n",
       " 'unanswered': 2374,\n",
       " 'clear': 22509,\n",
       " 'compete': 2388,\n",
       " 'far': 24948,\n",
       " 'complex': 24463,\n",
       " 'lemmas': 23898,\n",
       " 'even': 22508,\n",
       " 'semantics': 26691,\n",
       " 'designed': 17708,\n",
       " 'independent': 24648,\n",
       " 'date': 24535,\n",
       " 'systematically': 18813,\n",
       " 'clarify': 2447,\n",
       " 'open': 23338,\n",
       " 'mentioned': 8563,\n",
       " 'above': 3028,\n",
       " 'broad': 18977,\n",
       " 'were': 23296,\n",
       " 'conducted': 20933,\n",
       " 'compare': 17053,\n",
       " 'empirical': 26657,\n",
       " 'achieves': 24936,\n",
       " 'reaching': 2511,\n",
       " '1.7': 2516,\n",
       " 'top': 11749,\n",
       " 'scoring': 2521,\n",
       " '2013': 2525,\n",
       " 'shared': 18202,\n",
       " 'furthermore': 26654,\n",
       " 'norwegian': 10188,\n",
       " '17': 2568,\n",
       " 'reported': 20991,\n",
       " 'better': 21363,\n",
       " 'cross': 24544,\n",
       " 'experiment': 26607,\n",
       " 'improving': 25182,\n",
       " '32.3': 2636,\n",
       " 'gain': 2640,\n",
       " 'additional': 14086,\n",
       " 'insights': 21439,\n",
       " 'selected': 18023,\n",
       " 'classifier': 24624,\n",
       " 'being': 22730,\n",
       " 'discriminating': 2727,\n",
       " 'offers': 13466,\n",
       " 'localized': 2671,\n",
       " 'transfer': 23510,\n",
       " 'effects': 21204,\n",
       " 'since': 17831,\n",
       " 'lengths': 26553,\n",
       " 'captured': 26261,\n",
       " 'include': 18650,\n",
       " 'word': 26498,\n",
       " 'prefixes': 2707,\n",
       " 'suffixes': 2709,\n",
       " 'potential': 26716,\n",
       " 'generalize': 11336,\n",
       " 'analyzing': 11798,\n",
       " 'kinds': 21191,\n",
       " 'namely': 21649,\n",
       " 'choice': 20837,\n",
       " 'lexical': 26196,\n",
       " 'morphological': 24188,\n",
       " 'differences': 26340,\n",
       " 'goal': 11149,\n",
       " 'current': 24320,\n",
       " 'give': 23700,\n",
       " 'full': 26720,\n",
       " 'shed': 26333,\n",
       " 'widely': 20454,\n",
       " 'adopted': 26575,\n",
       " 'summary': 21496,\n",
       " 'content': 24809,\n",
       " 'follow': 3936,\n",
       " 'protocol': 2795,\n",
       " 'gold': 20553,\n",
       " 'summaries': 21532,\n",
       " 'called': 26564,\n",
       " 'paradigm': 11523,\n",
       " 'falls': 2817,\n",
       " 'short': 25648,\n",
       " 'less': 24689,\n",
       " 'accurate': 21901,\n",
       " 'single': 16638,\n",
       " 'assessment': 21049,\n",
       " 'third': 2864,\n",
       " 'technique': 25230,\n",
       " 'evaluations': 25748,\n",
       " 'expanding': 2871,\n",
       " 'chosen': 2898,\n",
       " 'quantifying': 2886,\n",
       " 'source': 23340,\n",
       " 'its': 24943,\n",
       " 'appropriately': 2897,\n",
       " 'produces': 25039,\n",
       " 'scores': 20529,\n",
       " 'replicate': 24442,\n",
       " 'assessments': 2906,\n",
       " 'increasing': 26644,\n",
       " 'pseudomodels': 2950,\n",
       " 'contain': 23609,\n",
       " 'form': 21486,\n",
       " 'higher': 18698,\n",
       " 'correlations': 2965,\n",
       " 'judgments': 21124,\n",
       " 'compared': 24687,\n",
       " 'feasibility': 16498,\n",
       " 'another': 22031,\n",
       " '—': 25667,\n",
       " 'pool': 2995,\n",
       " 'comparison': 25595,\n",
       " 'consensus': 3012,\n",
       " 'impressively': 3016,\n",
       " 'rankings': 3027,\n",
       " 'achieving': 19857,\n",
       " 'correlation': 17334,\n",
       " '0.9': 3029,\n",
       " 'integrated': 9769,\n",
       " 'derived': 25493,\n",
       " 'identifies': 3042,\n",
       " 'aligns': 3044,\n",
       " 'bilingual': 18739,\n",
       " 'nes': 3104,\n",
       " 'chinese': 26627,\n",
       " 'motivated': 26305,\n",
       " 'following': 18652,\n",
       " 'observations': 18653,\n",
       " '1': 25226,\n",
       " 'whether': 21013,\n",
       " 'ne': 3277,\n",
       " 'semantically': 12507,\n",
       " 'phonetically': 3075,\n",
       " 'depends': 19655,\n",
       " 'greatly': 10074,\n",
       " 'type': 21721,\n",
       " '2': 25234,\n",
       " 'aligned': 14491,\n",
       " 'pair': 14273,\n",
       " 'should': 25514,\n",
       " 'share': 19366,\n",
       " '3': 26508,\n",
       " 'initially': 3163,\n",
       " 'detected': 3164,\n",
       " 'act': 10149,\n",
       " 'anchors': 16218,\n",
       " 'further': 26269,\n",
       " 'candidates': 3116,\n",
       " 'proposes': 26490,\n",
       " 'mode': 3128,\n",
       " 'ratio': 3129,\n",
       " 'feature': 24983,\n",
       " 'defined': 26460,\n",
       " 'proportion': 3135,\n",
       " 'internal': 15585,\n",
       " 'tokens': 16466,\n",
       " 'enforces': 3146,\n",
       " 'consistency': 18260,\n",
       " 'constraint': 25485,\n",
       " 'utilizes': 16696,\n",
       " 'likelihoods': 3158,\n",
       " 'insensitive': 3183,\n",
       " 'f': 26635,\n",
       " 'score': 20792,\n",
       " 'identified': 20986,\n",
       " 'increases': 22107,\n",
       " '78.4': 3193,\n",
       " '88.0': 3196,\n",
       " '12.2': 3199,\n",
       " '–': 23790,\n",
       " 'alignment': 23695,\n",
       " 'sensitive': 20024,\n",
       " '68.4': 3223,\n",
       " '83.0': 3226,\n",
       " '21.3': 3229,\n",
       " 'demonstrates': 3240,\n",
       " 'robustness': 14076,\n",
       " 'domains': 24708,\n",
       " 'semi': 12101,\n",
       " 'supervised': 24207,\n",
       " 'boosts': 3274,\n",
       " 'knowing': 3286,\n",
       " 'degree': 26475,\n",
       " 'widespread': 3295,\n",
       " 'including': 26445,\n",
       " 'dialogue': 17793,\n",
       " 'created': 21798,\n",
       " 'lexicons': 6587,\n",
       " 'opposites': 3599,\n",
       " 'hot': 3463,\n",
       " 'cold': 3470,\n",
       " 'antipodals': 3333,\n",
       " 'complementaries': 3335,\n",
       " 'gradable': 3338,\n",
       " 'they': 26018,\n",
       " 'list': 14921,\n",
       " 'yet': 19803,\n",
       " 'warm': 3378,\n",
       " 'tropical': 3459,\n",
       " 'freezing': 3466,\n",
       " 'contrasting': 16409,\n",
       " 'hypothesis': 21246,\n",
       " 'if': 24024,\n",
       " 'b': 3437,\n",
       " 'c': 13652,\n",
       " 'd': 3439,\n",
       " 'strongly': 24316,\n",
       " 'exists': 3449,\n",
       " 'will': 26019,\n",
       " 'call': 15619,\n",
       " 'begin': 9846,\n",
       " 'crowdsourcing': 10817,\n",
       " 'determine': 20624,\n",
       " 'agreement': 21145,\n",
       " 'concept': 21069,\n",
       " 'oppositeness': 3500,\n",
       " 'flesh': 3511,\n",
       " 'key': 24337,\n",
       " 'relies': 24156,\n",
       " 'statistics': 4238,\n",
       " 'roget': 3547,\n",
       " 'thesaurus': 3550,\n",
       " 'four': 25676,\n",
       " 'evaluated': 26611,\n",
       " 'solving': 23693,\n",
       " 'distinguishing': 10058,\n",
       " 'synonyms': 6378,\n",
       " 'parts': 16912,\n",
       " 'obtains': 3610,\n",
       " 'precision': 8126,\n",
       " 'outperforming': 21174,\n",
       " 'focused': 16728,\n",
       " 'coreference': 3700,\n",
       " 'resolution': 3701,\n",
       " 'consists': 3643,\n",
       " 'determining': 8737,\n",
       " 'discourse': 22531,\n",
       " 'refer': 12393,\n",
       " 'contributions': 24529,\n",
       " 'i': 22053,\n",
       " 'satisfaction': 25486,\n",
       " 'hypergraph': 3681,\n",
       " 'relaxation': 24887,\n",
       " 'labeling': 12805,\n",
       " ...}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T14:03:36.343247Z",
     "start_time": "2022-11-18T14:03:36.304374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    }
   ],
   "source": [
    "# check length of all abstract\n",
    "max_seq = 0\n",
    "seq = []\n",
    "for abstract in file_list:\n",
    "#     print(abstract)\n",
    "    with open(abstract,'r', errors='replace') as f:\n",
    "        for token_label in f.read().splitlines():\n",
    "            # select exclude empty line because some annotator not follow this rule.\n",
    "            if token_label != '':\n",
    "                # some line does not use tab '\\t'\n",
    "                if not token_label.__contains__('\\t'):\n",
    "    #                 print(token_label)\n",
    "                    #split word and term by space\n",
    "                    token = token_label.split()[0]\n",
    "                elif token_label.__contains__('\\t'):\n",
    "                    #split word and term by tab\n",
    "                    token = token_label.split('\\t')[0]\n",
    "                else:\n",
    "                    print('# '+str(token_label)+abstract+' #')\n",
    "                \n",
    "                if token == '.':\n",
    "                    seq = []\n",
    "                else:\n",
    "                    seq.append(token)\n",
    "                    \n",
    "                if len(seq)> max_seq:\n",
    "                    max_seq = len(seq)\n",
    "#                     print(max_seq)\n",
    "print(max_seq)\n",
    "# becasue the highest seq length is around 175 token. so we decide we chose the sequence length is only 10 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T14:05:51.890843Z",
     "start_time": "2022-11-18T14:05:51.882889Z"
    }
   },
   "outputs": [],
   "source": [
    "file_train = _find_files('../Dataset/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T14:16:41.974913Z",
     "start_time": "2022-11-18T14:16:41.826776Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pair = []\n",
    "\n",
    "# create sequence of token with sequnce leght of 10 tokens. and sequence of label with 10 labels\n",
    "for train_file in file_train:\n",
    "    with open(train_file) as f:\n",
    "        for token_label in f.read().splitlines():\n",
    "            if token_label != '':\n",
    "                if not token_label.__contains__('\\t'):\n",
    "                    token = token_label.split()[0]\n",
    "                    label = token_label.split()[1]\n",
    "#                     train_pair.append([token,label]) \n",
    "                elif token_label.__contains__('\\t'):\n",
    "                    token = token_label.split('\\t')[0]\n",
    "                    label = token_label.split('\\t')[1]\n",
    "#                     train_pair.append([token,label])\n",
    "                else:\n",
    "                     print('# '+str(token_label)+train_file+' #')\n",
    "            \n",
    "            train_pair.append([token.lower(),label])\n",
    "\n",
    "# with open(train_sentences_file) as f:\n",
    "#     for sentence in f.read().splitlines():\n",
    "#         #replace each token by its index if it is in vocab\n",
    "#         #else use index of UNK\n",
    "#         s = [vocab[token] if token in self.vocab \n",
    "#             else vocab['UNK']\n",
    "#             for token in sentence.split(' ')]\n",
    "#         train_sentences.append(s)\n",
    "\n",
    "# with open(train_labels_file) as f:\n",
    "#     for sentence in f.read().splitlines():\n",
    "#         #replace each label by its index\n",
    "#         l = [tag_map[label] for label in sentence.split(' ')]\n",
    "#         train_labels.append(l)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T14:16:52.659880Z",
     "start_time": "2022-11-18T14:16:52.655670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21979"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T14:27:23.369698Z",
     "start_time": "2022-11-18T14:27:23.343655Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prepare at batch of sequence\n",
    "seq_token_list = []\n",
    "seq_token = []\n",
    "seq_label_list = []\n",
    "seq_label = []\n",
    "for token_label in train_pair:\n",
    "    if (len(seq_token) == 10) and (len(seq_label) == 10):\n",
    "        seq_token_list.append(seq_token)\n",
    "        seq_label_list.append(seq_label)\n",
    "        seq_token = []\n",
    "        seq_label = []\n",
    "    else:\n",
    "        seq_token.append(token_label[0])\n",
    "        seq_label.append(token_label[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T14:28:25.142057Z",
     "start_time": "2022-11-18T14:28:25.137805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_token_list[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T14:36:50.857206Z",
     "start_time": "2022-11-18T14:36:50.851503Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "max_len = 16\n",
    "batch_size = 64\n",
    "embed_size = 300\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée un tableau de dimension len(text) × max_len, et on le remplit de 0\n",
    "X = torch.zeros(len(texts), max_len, dtype=torch.long)\n",
    "\n",
    "# On remplit le tensor ligne par ligne avec nos textes convertis en nombres entiers\n",
    "for i, int_text in enumerate(int_tokens): # Pour chaque texte\n",
    "    if len(int_text) < max_len: # Si le texte est trop court\n",
    "        int_text = int_text + [len(token2int)] * (max_len - len(int_text)) # Alors on lui rajoute des tokens vides jusqu'à\n",
    "        # atteindre la bonne longueur\n",
    "    X[i] = torch.LongTensor(int_text[:max_len]) # On remplit la rangée correspondante (et on coupe à max_len tokens)\n",
    "\n",
    "# Même chose pour Y\n",
    "Y = torch.zeros(len(texts), max_len, dtype=torch.long)\n",
    "for i, int_label in enumerate(int_labels):\n",
    "    if len(int_label) < max_len:\n",
    "        int_label = int_label + [len(label2int)] * (max_len - len(int_label))\n",
    "    Y[i] = torch.LongTensor(int_label[:max_len])\n",
    "\n",
    "print(X.size())\n",
    "print(Y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T14:50:19.038748Z",
     "start_time": "2022-11-18T14:50:19.032527Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T15:06:14.195882Z",
     "start_time": "2022-11-18T15:06:14.159039Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [108]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# c-a-d les embeddings qu'on vient de créer à la ligne du dessus\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(output))\n\u001b[0;32m---> 16\u001b[0m rnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m rnn_model\n",
      "Input \u001b[0;32mIn [108]\u001b[0m, in \u001b[0;36mRNN.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(\u001b[43mvocab_size\u001b[49m, embed_size, padding_idx\u001b[38;5;241m=\u001b[39mtoken2int[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<eos>\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(embeddings, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mGRU(embed_size, hidden_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, bidirectional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size, padding_idx=token2int['<eos>'])\n",
    "        self.embed.weight = nn.Parameter(embeddings, requires_grad=False)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, bias=False, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.decision = nn.Linear(hidden_size * 1 * 1, len(label2int))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embed = self.embed(x)\n",
    "        output, hidden = self.rnn(embed) # On veut appeler notre réseau de neurones sur la sortie de la couche précédente\n",
    "        # c-a-d les embeddings qu'on vient de créer à la ligne du dessus\n",
    "        return self.decision(self.dropout(output))\n",
    "\n",
    "rnn_model = RNN()\n",
    "rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(index):\n",
    "        \"\"\"Return a data sample (=image) for a given index, along with the name of the corresponding pokemon.\"\"\"\n",
    "        \n",
    "        # TO DO:\n",
    "        # - get the image path corresponding to 'index' (use the list 'self.image_path_list')\n",
    "        # - get the pokemon name\n",
    "        # - load the image into a numpy array x\n",
    "        # - transform x into a pytorch tensor of type 'float'\n",
    "        # - return the tensor x and the pokemon name\n",
    "#         image_path = image_path_list[index]\n",
    "#         label = image_path.split('/')[-2]\n",
    "#         label = self.class_to_idx[label]\n",
    "#         x = io.imread(image_path)\n",
    "#         x = torch.tensor(x, dtype=float)\n",
    "        \n",
    "        return x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T12:42:13.372577Z",
     "start_time": "2022-11-16T12:42:13.368306Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = []\n",
    "labels = []\n",
    "token_label = []\n",
    "for word in lines:\n",
    "    word = word.replace('\\n', '')\n",
    "    token_label.append(word.split('\\t'))\n",
    "# #     print(token_label[-1])\n",
    "#     labels.append(token_label[1])\n",
    "#     tokens.append(token_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Code to get tokenized/segmented text:\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# doc = nlp(text10)\n",
    "# for sent in doc.sents:\n",
    "#     for token in sent:\n",
    "#         print(token.text+\"\\tO\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_dir):\n",
    "        \"\"\"Initialize the attributes of the object of the class.\"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.image_path_list = sorted(self._find_files(image_dir))\n",
    "        self.classes = self._get_class()\n",
    "        self.class_to_idx  = self._get_class_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the size of the dataset.\"\"\"\n",
    "        return len(self.image_path_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return a data sample (=image) for a given index, along with the name of the corresponding pokemon.\"\"\"\n",
    "        \n",
    "        # TO DO:\n",
    "        # - get the image path corresponding to 'index' (use the list 'self.image_path_list')\n",
    "        # - get the pokemon name\n",
    "        # - load the image into a numpy array x\n",
    "        # - transform x into a pytorch tensor of type 'float'\n",
    "        # - return the tensor x and the pokemon name\n",
    "        image_path = self.image_path_list[index]\n",
    "        label = image_path.split('/')[-2]\n",
    "        label = self.class_to_idx[label]\n",
    "        x = io.imread(image_path)\n",
    "        x = torch.tensor(x, dtype=float)\n",
    "        \n",
    "        return x, label\n",
    "\n",
    "    def _find_files(self, directory, pattern='*.jpeg'):\n",
    "        \"\"\"Recursively find all files matching the pattern.\"\"\"\n",
    "        image_path_list = []\n",
    "        for root, dirnames, filenames in os.walk(directory):\n",
    "            for filename in fnmatch.filter(filenames, pattern):\n",
    "                image_path_list.append(os.path.join(root, filename))\n",
    "        return image_path_list\n",
    "    \n",
    "    def _get_class(self):\n",
    "        classes = []\n",
    "        for path in self.image_path_list:\n",
    "            class_image = path.split('/')[2]\n",
    "            if class_image not in classes:\n",
    "                classes.append(class_image)\n",
    "        return classes\n",
    "    \n",
    "    def _get_class_index(self):\n",
    "        idx_to_class = {i:j for i, j in enumerate(self.classes)}\n",
    "        class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
    "        return class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can initialize the dataset by providing the directory of the image corpus data\n",
    "image_dir = 'Dataset/train'\n",
    "dataset = XrayDataset(image_dir=image_dir)\n",
    "\n",
    "# You can use the '_find_files' method to get the list of images paths\n",
    "image_path_list = dataset._find_files(image_dir)\n",
    "\n",
    "# Equivalently, since this list is stored as an inner attribute, you can access it directly:\n",
    "image_path_list = dataset.image_path_list\n",
    "\n",
    "# Display all file paths\n",
    "for l in image_path_list:\n",
    "    print(l)\n",
    "print('Number of images in the list', len(image_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Dataset/train'\n",
    "val_dir = 'Dataset/val'\n",
    "test_dir = 'Dataset/test'\n",
    "train_data = XrayDataset(image_dir=train_dir)\n",
    "val_data = XrayDataset(image_dir=val_dir)\n",
    "test_data = XrayDataset(image_dir=test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size (=number of samples/images in each batch) and create the dataloader\n",
    "batch_size = 5\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DNN",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1678ca5ab7b59e8b94516e5d5af75562d2ba273177333df7549ca965526dd05f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
